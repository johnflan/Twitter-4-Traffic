\subsection{Clustering}
The behaviour of users of social media in a specific timeframe of each day of
the week tend to follow a pattern. Especially if one looks at results of social
media usage considering the location from where social data were submitted,
they can see that pattern. For this project, the interest is on traffic social
data.
Using that theory, traffic disruptions can be detected through the unusual use
of social media. This way the detected data will be about unusual traffic, so
it would be able to show an accident or a closed road etc. In this project and
because people don't tend to use social media that much about traffic yet we
tested that theory using general social data and not only about traffic.
In order to do that, static clusters had to be created first. These clusters
represent the "normal" behaviour of the social media users. For all clustering
k-means was used due to its simplicity. The static data used in the project are
from a time frame of every day. After that a timeslice data are computed for
the same timeframe of a specific day.
The static data and the timeslice data are then compared, because unusual
behaviour is what is important. For the comparison, each cluster is considered
to be a Gaussian distribution. The Kullback-Leibler divergence is then applied
to the timeslice clusters comparing them to the static clusters. The value
returned from that function is a real number larger or equals to zero. The
closest this number is to zero, the more the distributions are alike.

\subsection{Gamification}

\subsection{Analysis of other sources}
As the aim of this project is providing information to the user about traffic disruptions, more sources can 
easily be used for acquiring more information about disruptions in London and other areas. Such examples 
of sources would be news reports published in various websites. These reports could include accidents, general traffic or even 
bad road conditions due to the weather. Moreover, there exist TfL Twitter bots that frequently tweet
about traffic disruptions. Another source that can be used is Facebook. Data regarding traffic can be
extracted from posts, comments or even public groups whose current location is London.

\subsection{Enhanced tweet geocoding}
For some reasons, mobile users cannot tweet the right position where the disruption is. Geolocation needs be double-checked by comparing with geography data stored in server before inserted into database. What's more, some geolocations of street stored in the database will change in the future. Those data should be checked and updated periodically. Google maps geocoding function can be implemented to provide the latest information for those street addresses. Algorithm for extracting street address from text need to be optimized to get more accurate results. Then those results can be used to receive responding longitude and latitude from Google Map. Meanwhile, database can be expanded to receive more tweets from Twitter for application users to provide traffic disruptions even out of London.
